{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit risk modelling project - A machine learning model\n",
    "Based on the dataset related to credit risk and contains information about individuals who have taken loans, I develop a machine learning model to predict the probability of loan default based on various financial and demographic factors of the borrowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing and importing necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('credit_risk_dataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Visualize the distribution of the loan status\n",
    "sns.countplot(x='loan_status', data=df)\n",
    "plt.title('Distribution of Loan Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the correlation matrix\n",
    "# Drop non-numeric columns\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df_numeric.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Convert categorical variables into dummy variables\n",
    "df = pd.get_dummies(df, drop_first=True) ## Dropping the first category with drop_first=True prevents multicollinearity, which can lead to instability in model coefficients and inaccurate predictions.\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "# the features X are the input variables used by the model to make predictions\n",
    "X = df.drop('loan_status', axis=1) # removes the 'loan_status' column from the DataFrame 'df'\n",
    "# Reason: 'loan_status' is the target variable that indicates whether the loan is in default (1) or not (0). It is the variable you want to predict, so it should not be included in the features.\n",
    "\n",
    "# the target y is the variable that the model will learn to predict\n",
    "y = df['loan_status']\n",
    "# Reason: The 'loan_status' column contains the outcome or label (default or not default) that the model aims to predict based on the features.\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # 30% of the data will be used for testing, and the remaining 70% will be used for training.\n",
    "# Using a fixed 'random_state' allows you to get the same train-test split every time you run the code\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# This approach ensures that both the training and testing sets are on the same scale, facilitating more reliable model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Impute missing values in X_train and X_test\n",
    "imputer = SimpleImputer(strategy='mean')  # missing values should be replaced with the mean of each feature\n",
    "X_train = imputer.fit_transform(X_train) # Computes the mean of each feature using the training data, then replaces missing values in 'X_train'\n",
    "X_test = imputer.transform(X_test) # Applies the same statistics computed from 'X_train' to impute missing values in 'X_test'\n",
    "\n",
    "# Now fit the logistic regression model\n",
    "log_reg = LogisticRegression() # modelling the relationship between the input features and the binary target variable using a logistic function\n",
    "log_reg.fit(X_train, y_train) # training the logistic regression model using the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = log_reg.predict(X_test) # Uses the trained logistic regression model to predict the target variable ('loan_status') for the test set features ('X_test').\n",
    "\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred)) # Generates a detailed report of the modelâ€™s performance, comparing the true values (y_test) with the predicted values (y_pred)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of the Classification Report:\n",
    "\n",
    "1. **Class 0 (Non-Default) Metrics**:\n",
    "   - **Precision**: 0.88\n",
    "     - This means 88% of the loans predicted as non-defaults were actually non-defaults.\n",
    "   - **Recall**: 0.95\n",
    "     - The model correctly identified 95% of all actual non-defaults.\n",
    "   - **F1-Score**: 0.92\n",
    "     - The harmonic mean of precision and recall, showing a strong performance in predicting non-defaults.\n",
    "\n",
    "2. **Class 1 (Default) Metrics**:\n",
    "   - **Precision**: 0.77\n",
    "     - This means 77% of the loans predicted as defaults were actual defaults.\n",
    "   - **Recall**: 0.56\n",
    "     - The model correctly identified 56% of all actual defaults, indicating some defaults were missed.\n",
    "   - **F1-Score**: 0.65\n",
    "     - This lower F1-score suggests the model is less effective in predicting defaults compared to non-defaults.\n",
    "\n",
    "3. **Overall Metrics**:\n",
    "   - **Accuracy**: 0.86\n",
    "     - The overall accuracy of the model is 86%, meaning it correctly classified 86% of all loans.\n",
    "   - **Macro Average** (average of precision, recall, and F1-score for both classes):\n",
    "     - **Precision**: 0.83, **Recall**: 0.75, **F1-Score**: 0.78\n",
    "     - This provides a balanced view of performance across classes.\n",
    "   - **Weighted Average** (weighted by support):\n",
    "     - **Precision**: 0.86, **Recall**: 0.86, **F1-Score**: 0.86\n",
    "     - These metrics are similar to the accuracy and reflect the overall model performance considering the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of the Confusion Matrix:\n",
    "\n",
    "1. **True Negatives (TN)**: 7,247\n",
    "   - The model correctly predicted 7,247 instances as non-defaults (actual non-defaults predicted as non-defaults).\n",
    "\n",
    "2. **False Positives (FP)**: 366\n",
    "   - The model incorrectly predicted 366 instances as defaults when they were actually non-defaults (false alarms).\n",
    "\n",
    "3. **False Negatives (FN)**: 956\n",
    "   - The model incorrectly predicted 956 instances as non-defaults when they were actually defaults (missed defaults).\n",
    "\n",
    "4. **True Positives (TP)**: 1,206\n",
    "   - The model correctly predicted 1,206 instances as defaults (actual defaults predicted as defaults).\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "- **High True Negatives**: The model is effective at correctly identifying non-defaults, as shown by the large number of true negatives (7,247).\n",
    "  \n",
    "- **Challenges with False Negatives**: There are 956 false negatives, indicating that the model missed a significant number of actual defaults. This suggests the model could be underestimating the risk of default for some loans.\n",
    "\n",
    "- **Moderate True Positives and False Positives**: The model has correctly identified a moderate number of defaults (1,206), but it also has a smaller number of false positives (366), which indicates reasonable precision but room for improvement in identifying defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Receiver Operating Characteristic (ROC) curve and calculate the Area Under the Curve (AUC)\n",
    "# \n",
    "\n",
    "y_pred_prob = log_reg.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC Curve: Visualizes the performance of the model across all classification thresholds, showing how well the model separates the classes.\n",
    "- AUC: Provides a single metric that captures the model's overall ability to discriminate between positive and negative classes.\n",
    "A higher AUC indicates better performance, with values closer to 1.0 showing strong discrimination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of the ROC Curve:\n",
    "\n",
    "1. **Shape of the ROC Curve**:\n",
    "   - The curve shows a good balance between True Positive Rate (TPR) and False Positive Rate (FPR).\n",
    "   - The curve rises quickly towards the top-left corner, indicating that the model is effective at distinguishing between positive and negative classes at various thresholds.\n",
    "\n",
    "2. **AUC (Area Under the Curve)**:\n",
    "   - The AUC value of **0.87** suggests that the model has strong discriminatory power.\n",
    "   - An AUC of 0.87 means that there is an 87% chance that the model will correctly differentiate between a randomly chosen positive instance (default) and a randomly chosen negative instance (non-default).\n",
    "   - Values close to 1 indicate excellent model performance, while values closer to 0.5 suggest a model with no discriminatory power.\n",
    "\n",
    "3. **Diagonal Reference Line**:\n",
    "   - The dashed line (diagonal from (0,0) to (1,1)) represents the performance of a random classifier with AUC = 0.5.\n",
    "   - The model's ROC curve is well above this line, confirming that it performs significantly better than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Trained Model and Scaler:\n",
    "import joblib\n",
    "\n",
    "# Save the trained logistic regression model\n",
    "joblib.dump(log_reg, 'trained_model.pkl')\n",
    "\n",
    "# Save the scaler used for transforming the data\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "print(\"Model and scaler have been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the newly developed machine learning model to predict the probability of default for a new customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Version 1: Simple version - modify the input of new customer's information to obtain the probability of default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def predict_default_probability(\n",
    "    age, income, home_ownership, emp_length, loan_intent, loan_grade, \n",
    "    loan_amnt, loan_int_rate, loan_percent_income, cb_default, cred_hist_length, \n",
    "    model, scaler, feature_columns):\n",
    "    \"\"\"\n",
    "    Predicts the probability of default for a new customer.\n",
    "\n",
    "    Parameters:\n",
    "    - age (int): Age of the customer\n",
    "    - income (float): Income of the customer\n",
    "    - home_ownership (str): Home ownership status (RENT, MORTGAGE, OWN, OTHER)\n",
    "    - emp_length (int): Employment length in years\n",
    "    - loan_intent (str): Purpose of the loan (PERSONAL, EDUCATION, MEDICAL, HOMEIMPROVEMENT, DEBTCONSOLIDATION, VENTURE)\n",
    "    - loan_grade (str): Loan grade (B, C, D, E, F, G)\n",
    "    - loan_amnt (float): Amount of the loan\n",
    "    - loan_int_rate (float): Interest rate of the loan\n",
    "    - loan_percent_income (float): Percentage of income dedicated to loan payments\n",
    "    - cb_default (str): Credit bureau default on file ('Y' or 'N')\n",
    "    - cred_hist_length (int): Length of credit history\n",
    "    - model (sklearn model): Trained logistic regression model\n",
    "    - scaler (sklearn scaler): Trained scaler for feature scaling\n",
    "    - feature_columns (list): List of feature columns from the training set\n",
    "    \n",
    "    Returns:\n",
    "    - float: Predicted probability of default\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the new customer data as a dictionary\n",
    "    new_customer = {\n",
    "        'person_age': age,\n",
    "        'person_income': income,\n",
    "        'person_home_ownership_RENT': 1 if home_ownership == 'RENT' else 0,\n",
    "        'person_home_ownership_MORTGAGE': 1 if home_ownership == 'MORTGAGE' else 0,\n",
    "        'person_home_ownership_OWN': 1 if home_ownership == 'OWN' else 0,\n",
    "        'person_home_ownership_OTHER': 1 if home_ownership == 'OTHER' else 0,\n",
    "        'person_emp_length': emp_length,\n",
    "        'loan_intent_PERSONAL': 1 if loan_intent == 'PERSONAL' else 0,\n",
    "        'loan_intent_EDUCATION': 1 if loan_intent == 'EDUCATION' else 0,\n",
    "        'loan_intent_MEDICAL': 1 if loan_intent == 'MEDICAL' else 0,\n",
    "        'loan_intent_HOMEIMPROVEMENT': 1 if loan_intent == 'HOMEIMPROVEMENT' else 0,\n",
    "        'loan_intent_DEBTCONSOLIDATION': 1 if loan_intent == 'DEBTCONSOLIDATION' else 0,\n",
    "        'loan_intent_VENTURE': 1 if loan_intent == 'VENTURE' else 0,\n",
    "        'loan_grade_B': 1 if loan_grade == 'B' else 0,\n",
    "        'loan_grade_C': 1 if loan_grade == 'C' else 0,\n",
    "        'loan_grade_D': 1 if loan_grade == 'D' else 0,\n",
    "        'loan_grade_E': 1 if loan_grade == 'E' else 0,\n",
    "        'loan_grade_F': 1 if loan_grade == 'F' else 0,\n",
    "        'loan_grade_G': 1 if loan_grade == 'G' else 0,\n",
    "        'loan_amnt': loan_amnt,\n",
    "        'loan_int_rate': loan_int_rate,\n",
    "        'loan_percent_income': loan_percent_income,\n",
    "        'cb_person_default_on_file_Y': 1 if cb_default == 'Y' else 0,\n",
    "        'cb_person_cred_hist_length': cred_hist_length\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame for the new customer data\n",
    "    new_customer_df = pd.DataFrame([new_customer])\n",
    "\n",
    "    # Ensure the DataFrame has the same columns as expected by the model\n",
    "    for col in feature_columns:\n",
    "        if col not in new_customer_df.columns:\n",
    "            new_customer_df[col] = 0  # Add missing columns with 0\n",
    "\n",
    "    # Reorder columns to match the training data\n",
    "    new_customer_df = new_customer_df[feature_columns]\n",
    "\n",
    "    # Apply the same scaling\n",
    "    new_customer_scaled = scaler.transform(new_customer_df)\n",
    "\n",
    "    # Predict the probability of default\n",
    "    probability_of_default = model.predict_proba(new_customer_scaled)[0][1]\n",
    "\n",
    "    return probability_of_default\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To use this function, pass in the details of the new customer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: to estimate the default probability, simpply modify the 'age', 'income', 'home_ownership', 'emp_length', 'loan_intent', 'loan_grade', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_default', 'cred_hist_length' below and then run the code\n",
    "\n",
    "probability = predict_default_probability(\n",
    "    age=35,                             # can be modified\n",
    "    income=60000,                       # can be modified\n",
    "    home_ownership='MORTGAGE',          # can be modified\n",
    "    emp_length=6,                       # can be modified\n",
    "    loan_intent='PERSONAL',             # can be modified\n",
    "    loan_grade='C',                     # can be modified\n",
    "    loan_amnt=10000,                    # can be modified\n",
    "    loan_int_rate=14.5,                 # can be modified\n",
    "    loan_percent_income=0.2,            # can be modified\n",
    "    cb_default='N',                     # can be modified\n",
    "    cred_hist_length=5,                 # can be modified\n",
    "    model=log_reg, \n",
    "    scaler=scaler, \n",
    "    feature_columns=X.columns\n",
    ")\n",
    "\n",
    "print(f\"The predicted probability of default is: {probability:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Version 2: Interactive Function version - Enter each detail of the new customer when asked to calculate the probability of default\n",
    "\n",
    "Hereâ€™s an enhanced version of the function that will interactively prompt you to enter each piece of customer information. The function will guide you through entering details such as age, income, home ownership, and other relevant factors. After gathering all the inputs, it will calculate and display the probability of default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict_default_probability_interactive(model, scaler, feature_columns):\n",
    "    \"\"\"\n",
    "    Interactively collects customer information and predicts the probability of default.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (sklearn model): Trained logistic regression model\n",
    "    - scaler (sklearn scaler): Trained scaler for feature scaling\n",
    "    - feature_columns (list): List of feature columns from the training set\n",
    "    \n",
    "    Returns:\n",
    "    - float: Predicted probability of default\n",
    "    \"\"\"\n",
    "    \n",
    "    # Collect inputs from the user\n",
    "    age = int(input(\"Enter the customer's age: \"))\n",
    "    income = float(input(\"Enter the customer's income: \"))\n",
    "    \n",
    "    # Home ownership input\n",
    "    home_ownership = input(\"Enter the customer's home ownership status (RENT, MORTGAGE, OWN, OTHER): \").strip().upper()\n",
    "    \n",
    "    # Employment length\n",
    "    emp_length = int(input(\"Enter the customer's employment length (in years): \"))\n",
    "    \n",
    "    # Loan intent\n",
    "    loan_intent = input(\"Enter the customer's loan intent (PERSONAL, EDUCATION, MEDICAL, HOMEIMPROVEMENT, DEBTCONSOLIDATION, VENTURE): \").strip().upper()\n",
    "    \n",
    "    # Loan grade\n",
    "    loan_grade = input(\"Enter the customer's loan grade (B, C, D, E, F, G): \").strip().upper()\n",
    "    \n",
    "    # Loan amount\n",
    "    loan_amnt = float(input(\"Enter the loan amount: \"))\n",
    "    \n",
    "    # Loan interest rate\n",
    "    loan_int_rate = float(input(\"Enter the loan interest rate (as a percentage): \"))\n",
    "    \n",
    "    # Loan percent income\n",
    "    loan_percent_income = float(input(\"Enter the percentage of income dedicated to loan payments: \"))\n",
    "    \n",
    "    # Credit bureau default on file\n",
    "    cb_default = input(\"Is there a credit bureau default on file? (Y/N): \").strip().upper()\n",
    "    \n",
    "    # Credit history length\n",
    "    cred_hist_length = int(input(\"Enter the length of the customer's credit history (in years): \"))\n",
    "    \n",
    "    # Define the new customer data as a dictionary\n",
    "    new_customer = {\n",
    "        'person_age': age,\n",
    "        'person_income': income,\n",
    "        'person_home_ownership_RENT': 1 if home_ownership == 'RENT' else 0,\n",
    "        'person_home_ownership_MORTGAGE': 1 if home_ownership == 'MORTGAGE' else 0,\n",
    "        'person_home_ownership_OWN': 1 if home_ownership == 'OWN' else 0,\n",
    "        'person_home_ownership_OTHER': 1 if home_ownership == 'OTHER' else 0,\n",
    "        'person_emp_length': emp_length,\n",
    "        'loan_intent_PERSONAL': 1 if loan_intent == 'PERSONAL' else 0,\n",
    "        'loan_intent_EDUCATION': 1 if loan_intent == 'EDUCATION' else 0,\n",
    "        'loan_intent_MEDICAL': 1 if loan_intent == 'MEDICAL' else 0,\n",
    "        'loan_intent_HOMEIMPROVEMENT': 1 if loan_intent == 'HOMEIMPROVEMENT' else 0,\n",
    "        'loan_intent_DEBTCONSOLIDATION': 1 if loan_intent == 'DEBTCONSOLIDATION' else 0,\n",
    "        'loan_intent_VENTURE': 1 if loan_intent == 'VENTURE' else 0,\n",
    "        'loan_grade_B': 1 if loan_grade == 'B' else 0,\n",
    "        'loan_grade_C': 1 if loan_grade == 'C' else 0,\n",
    "        'loan_grade_D': 1 if loan_grade == 'D' else 0,\n",
    "        'loan_grade_E': 1 if loan_grade == 'E' else 0,\n",
    "        'loan_grade_F': 1 if loan_grade == 'F' else 0,\n",
    "        'loan_grade_G': 1 if loan_grade == 'G' else 0,\n",
    "        'loan_amnt': loan_amnt,\n",
    "        'loan_int_rate': loan_int_rate,\n",
    "        'loan_percent_income': loan_percent_income,\n",
    "        'cb_person_default_on_file_Y': 1 if cb_default == 'Y' else 0,\n",
    "        'cb_person_cred_hist_length': cred_hist_length\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame for the new customer data\n",
    "    new_customer_df = pd.DataFrame([new_customer])\n",
    "\n",
    "    # Ensure the DataFrame has the same columns as expected by the model\n",
    "    for col in feature_columns:\n",
    "        if col not in new_customer_df.columns:\n",
    "            new_customer_df[col] = 0  # Add missing columns with 0\n",
    "\n",
    "    # Reorder columns to match the training data\n",
    "    new_customer_df = new_customer_df[feature_columns]\n",
    "\n",
    "    # Apply the same scaling\n",
    "    new_customer_scaled = scaler.transform(new_customer_df)\n",
    "\n",
    "    # Predict the probability of default\n",
    "    probability_of_default = model.predict_proba(new_customer_scaled)[0][1]\n",
    "\n",
    "    print(f\"\\nThe predicted probability of default for the customer is: {probability_of_default:.2f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to Use the Interactive Function:** \n",
    "- Run the function in your Python environment.\n",
    "- The function will prompt you to enter each piece of customer information step by step.\n",
    "- After entering all the details, the function will calculate and display the probability of default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the trained model, scaler, and feature columns\n",
    "predict_default_probability_interactive(\n",
    "    model=log_reg, \n",
    "    scaler=scaler, \n",
    "    feature_columns=X.columns\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
